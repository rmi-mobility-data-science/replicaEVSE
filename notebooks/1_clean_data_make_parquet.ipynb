{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean the data and make parquet files\n",
    "\n",
    " The files we were given for the northwest region from replica have header rows embedded through out due to the way the google cloud on their end stacks things.\n",
    "\n",
    " Here we clean convert every column to strings and then remove those rows and save the data to parquet files which are easier to deal with.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from replicaEVSE import datautils as du\n",
    "import os\n",
    "import dask.dataframe as dd\n",
    "import pandas as pd\n",
    "\n",
    "datadir = '../../data/'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### path to the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datapath = '../../data/'\n",
    "popfile = 'northwest_2021_Q4_population.csv'\n",
    "tripsatfile = 'northwest_2021_Q4_saturday_trip.csv'\n",
    "tripthufile = 'northwest_2021_Q4_thursday_trip.csv'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load and convert all the data to strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_df = du.load_data(os.path.join(datapath, popfile))\n",
    "tripsat_df = du.load_data(os.path.join(datapath, tripsatfile))\n",
    "tripthu_df = du.load_data(os.path.join(datapath, tripthufile))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### clean the data of bad rows (embedded headers in the data) and return the dask data frames for inspection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_df = du.clean_pop_data(pop_df)\n",
    "tripsat_df = du.clean_trip_data(tripsat_df)\n",
    "tripthu_df = du.clean_trip_data(tripthu_df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Or we can use our wrapper to clean save the data in the parquet format to speed analysis later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "popparquet = 'northwest_2021_Q4_population.parquet'\n",
    "tripsatparquet = 'northwest_2021_Q4_saturday_trip.parquet'\n",
    "tripthuparquet = 'northwest_2021_Q4_thursday_trip.parquet'\n",
    "pop_df = pop_df.to_parquet(os.path.join(datapath, popparquet))\n",
    "tripsat_df = tripsat_df.to_parquet(os.path.join(datapath, tripsatparquet))\n",
    "tripthu_df = tripthu_df.to_parquet(os.path.join(datapath, tripthuparquet))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "popparquet = 'northwest_2021_Q4_population.parquet'\n",
    "tripthuparquet = 'northwest_2021_Q4_thursday_trip.parquet'\n",
    "df = dd.read_parquet(os.path.join(datapath, tripthuparquet))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make a joined table and save as parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get list of blockgroups\n",
    "gdf = pd.read_pickle(datadir+'/blockgroup_boundaries.pkl')\n",
    "bgrp_list = list(gdf.GEOID.values)\n",
    "\n",
    "trip_sat_ddf = dd.read_parquet(datadir+'/northwest_2021_Q4_saturday_trip.parquet')\n",
    "trip_thu_ddf = dd.read_parquet(datadir+'/northwest_2021_Q4_thursday_trip.parquet')\n",
    "\n",
    "# dtype_dict = {\"person_id\": str, \"home_cty\": \"category\", \"home_st\": \"category\"}\n",
    "dtype_dict = {\"person_id\": str, \"home_cty\": str, \"home_st\": str}\n",
    "counties = dd.read_parquet(datadir+'/population_counties_dataset.parquet', engine='pyarrow')\n",
    "\n",
    "pop_ddf = dd.read_parquet(datadir+'/northwest_2021_Q4_population.parquet')\n",
    "# pop_ddf = dd.merge(pop_ddf, counties, on='person_id', how='left')\n",
    "\n",
    "\n",
    "trip_sat_ddf['weekday'] = 'saturday'\n",
    "trip_thu_ddf['weekday'] = 'thursday'\n",
    "\n",
    "# stack the two dataframes\n",
    "trips = dd.concat([trip_sat_ddf, trip_thu_ddf], axis=0, keys=[\"saturday\", \"thursday\"])\n",
    "\n",
    "\n",
    "# only trips that end in WA\n",
    "trips_ddf = trips.loc[trips['destination_bgrp'].isin(bgrp_list)]\n",
    " \n",
    "merged_ddf = dd.merge(trips_ddf, pop_ddf, on='person_id', how='left')\n",
    "\n",
    "# Create charge_type column from travel_purpose column\n",
    "merged_ddf['charge_type'] = merged_ddf.travel_purpose\n",
    "\n",
    "merged_ddf['charge_type'] = merged_ddf.travel_purpose\n",
    "merged_ddf['charge_type'] = merged_ddf['charge_type'].where(\n",
    "    merged_ddf.charge_type.isin(\n",
    "    ['WORK', 'HOME']), 'PUBLIC')\n",
    "\n",
    "merged_ddf.to_parquet(datadir+'/wa_pop_and_trips.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### make sure the join worked\n",
    "# get list of blockgroups\n",
    "gdf = pd.read_pickle(datadir+'/blockgroup_boundaries.pkl')\n",
    "bgrp_list = list(gdf.GEOID.values)\n",
    "\n",
    "trip_sat_ddf = dd.read_parquet(datadir+'/northwest_2021_Q4_saturday_trip.parquet')\n",
    "trip_thu_ddf = dd.read_parquet(datadir+'/northwest_2021_Q4_thursday_trip.parquet')\n",
    "\n",
    "# dtype_dict = {\"person_id\": str, \"home_cty\": \"category\", \"home_st\": \"category\"}\n",
    "dtype_dict = {\"person_id\": str, \"home_cty\": str, \"home_st\": str}\n",
    "counties = dd.read_parquet(datadir+'/population_counties_dataset.parquet', engine='pyarrow')\n",
    "\n",
    "pop_ddf = dd.read_parquet(datadir+'/northwest_2021_Q4_population.parquet')\n",
    "# pop_ddf = dd.merge(pop_ddf, counties, on='person_id', how='left')\n",
    "\n",
    "\n",
    "trip_sat_ddf['weekday'] = 'saturday'\n",
    "trip_thu_ddf['weekday'] = 'thursday'\n",
    "\n",
    "# stack the two dataframes\n",
    "trips = dd.concat([trip_sat_ddf, trip_thu_ddf], axis=0, keys=[\"saturday\", \"thursday\"])\n",
    "\n",
    "\n",
    "# only trips that end in WA\n",
    "trips_ddf = trips.loc[trips['destination_bgrp'].isin(bgrp_list)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trips_into_wa_len = len(trips_ddf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trips_into_wa_len = 51727268"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trip persons who are also in population dataset\n",
    "trips_in_pop_ddf = trips_ddf.loc[trips_ddf['person_id'].isin(pop_ddf['person_id'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(pop_ddf['person_id'].unique().compute())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(trips_ddf['person_id'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "8538399/1e6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(merged_ddf['person_id'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
