{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import replicaEVSE.load_curve as sim\n",
    "import replicaEVSE.datautils as simdu\n",
    "import os\n",
    "import joblib\n",
    "import dask.dataframe as dd\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "datadir = '../../data/'\n",
    "mode = 'PRIVATE_AUTO'\n",
    "test = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#Created in the EIA_data_download.ipynb notebook\n",
    "existing_load=pd.read_csv(datadir+'EIA_demand_summary.csv') \n",
    "if test:\n",
    "    # df = pd.read_parquet(os.path.join(datadir, 'wa_pop_and_trips_subsample.parquet'))\n",
    "    df = pd.read_parquet(os.path.join(datadir, 'wa_pop_and_trips_sorted_county.parquet'))\n",
    "    df = df.head(10000)\n",
    "    df = df.loc[df['mode'] == mode]\n",
    "    simulation_id = 'dev'\n",
    "\n",
    "else: \n",
    "    # read in the joined trips and population data sets\n",
    "    merged_df = pd.read_parquet(os.path.join(datadir, 'wa_pop_and_trips_sorted_county.parquet'))\n",
    "\n",
    "    # right now, only look at private auto trips\n",
    "    df = merged_df.loc[merged_df['mode'] == mode]\n",
    "    # take out the mobile and commercial MHDV\n",
    "\n",
    "df = df[(df['building_type'] != 'mobile') & (df['building_type'] != None)]\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  sample by county: for now use a percent until we have the stock rollover model\n",
    "\n",
    "`ev_df` should be given to us to run. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_rollover = pd.read_csv(datadir+'LDV_pop_adjusted.csv')\n",
    "efficiency = pd.read_csv(datadir+'vehicle_inputs.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Personal Sedan EV 0.25\n",
      "Personal Sedan PHEV 80.0\n",
      "Personal Crossover EV 0.3\n",
      "Personal Crossover PHEV 80.0\n",
      "Personal Truck/SUV EV 0.49\n",
      "Personal Truck/SUV PHEV 80.0\n",
      "Commercial Sedan EV 0.25\n",
      "Commercial Sedan PHEV 80.0\n",
      "Commercial Crossover EV 0.3\n",
      "Commercial Crossover PHEV 80.0\n",
      "Commercial Truck/SUV EV 0.49\n",
      "Commercial Truck/SUV PHEV 80.0\n"
     ]
    }
   ],
   "source": [
    "personal = ['Personal Sedan', 'Personal Crossover', 'Personal Truck/SUV']\n",
    "commercial = ['Commercial Sedan', 'Commercial Crossover', 'Commercial Truck/SUV']\n",
    "for cartype in personal + commercial:\n",
    "    for powertrain in  ['EV', 'PHEV']:\n",
    "        cond = (efficiency['Vehicle_type']==cartype) & ~efficiency['Powertrain'].isin(['ICE-G', 'ICE-D', 'FCEV']) & (efficiency['Powertrain']==powertrain) & (efficiency['Vintage'] == 2022)\n",
    "        ef = efficiency[cond]['Efficiency'].values[0]\n",
    "        print(cartype, powertrain, ef)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "nev_df = stock_rollover[stock_rollover['Powertrain']=='EV'].copy()\n",
    "# nev_df = nev_df[nev_df['Vehicle_type']==segment].copy()\n",
    "nev_df = nev_df[nev_df['domicile'] != 'other'].copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2022</th>\n",
       "      <th>2035</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2363</th>\n",
       "      <td>1</td>\n",
       "      <td>2239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2367</th>\n",
       "      <td>49</td>\n",
       "      <td>6109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2374</th>\n",
       "      <td>190</td>\n",
       "      <td>21705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2378</th>\n",
       "      <td>34</td>\n",
       "      <td>22073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2385</th>\n",
       "      <td>133</td>\n",
       "      <td>82306</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>462 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      2022   2035\n",
       "0        0      1\n",
       "5        0      5\n",
       "9        0      0\n",
       "15       1     13\n",
       "19       0     77\n",
       "...    ...    ...\n",
       "2363     1   2239\n",
       "2367    49   6109\n",
       "2374   190  21705\n",
       "2378    34  22073\n",
       "2385   133  82306\n",
       "\n",
       "[462 rows x 2 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nev_df[['2022', '2035']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "235891\n",
      "235891\n",
      "616258\n",
      "616258\n",
      "1619946\n",
      "1619946\n",
      "3030386\n",
      "3030386\n"
     ]
    }
   ],
   "source": [
    "reduced_df = []\n",
    "unique_df = df.drop_duplicates(subset=['person_id'])[['person_id', 'destination_county', 'building_type']]\n",
    "for year in [2023, 2025, 2030, 2035]:\n",
    "    print(nev_df[str(year)].sum())\n",
    "    num_to_select = nev_df[str(year)].sum()\n",
    "    selected = unique_df.person_id.sample(n=num_to_select, replace=False, random_state=42)\n",
    "    \n",
    "    # grab only those selected people from the original dataframe\n",
    "    year_df = df[(df['person_id'].isin(selected))].copy()\n",
    "    year_df['year'] = year\n",
    "    reduced_df.append(year_df)\n",
    "    \n",
    "final_df = pd.concat(reduced_df)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3030386"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df[final_df['year'] == 2035]['person_id'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['activity_id', 'person_id', 'mode', 'travel_purpose',\n",
       "       'previous_activity_type', 'start_time', 'end_time', 'distance_miles',\n",
       "       'vehicle_type', 'origin_bgrp', 'origin_bgrp_lat', 'origin_bgrp_lng',\n",
       "       'destination_bgrp', 'destination_bgrp_lat', 'destination_bgrp_lng',\n",
       "       'origin_land_use_l1', 'origin_land_use_l2', 'origin_building_use_l1',\n",
       "       'origin_building_use_l2', 'destination_land_use_l1',\n",
       "       'destination_land_use_l2', 'destination_building_use_l1',\n",
       "       'destination_building_use_l2', 'origin_lat', 'origin_lng',\n",
       "       'destination_lat', 'destination_lng', 'weekday', 'household_id',\n",
       "       'BLOCKGROUP', 'BLOCKGROUP_work', 'BLOCKGROUP_school', 'TRACT',\n",
       "       'TRACT_work', 'TRACT_school', 'age_group', 'age', 'sex', 'race',\n",
       "       'ethnicity', 'individual_income_group', 'individual_income',\n",
       "       'employment', 'education', 'school_grade_attending', 'industry',\n",
       "       'household_role', 'subfamily_number', 'subfamily_relationship',\n",
       "       'commute_mode', 'tenure', 'migration', 'household_size',\n",
       "       'household_income_group', 'household_income', 'family_structure',\n",
       "       'vehicles', 'building_type', 'resident_type', 'language', 'lat', 'lng',\n",
       "       'lat_work', 'lng_work', 'lat_school', 'lng_school', 'wfh',\n",
       "       'charge_type', 'destination_county', 'year'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 96 concurrent workers.\n"
     ]
    }
   ],
   "source": [
    "seg_list = ['Personal Sedan',\n",
    " 'Personal Crossover',\n",
    " 'Personal Truck/SUV',\n",
    " 'Commercial Sedan',\n",
    " 'Commercial Crossover',\n",
    " 'Commercial Truck/SUV']\n",
    "\n",
    "datadir = '../../data/'\n",
    "\n",
    "existing_load=pd.read_csv(datadir+'EIA_demand_summary.csv') \n",
    "simulation_id = f'by_year_{str(year)}'\n",
    "charge_df_list = []\n",
    "loads_df_list = []\n",
    "workfrac_arr = np.linspace(0.2, 0.6, 4)\n",
    "multiunitfrac_arr = np.linspace(0.2, 0.6, 4)\n",
    "years = [2023, 2025, 2030, 2035]\n",
    "\n",
    "for year, workfrac, multiunitfrac  in zip(years, workfrac_arr, multiunitfrac_arr):\n",
    "    charge_df_seg_list = []\n",
    "    loads_df_seg_list = []\n",
    "    df_year = final_df[final_df['year'] == year]\n",
    "\n",
    "    number_of_chunks = 10000\n",
    "    df_list = np.array_split(df_year, number_of_chunks)\n",
    "\n",
    "    charge_sims = joblib.Parallel(verbose=10, n_jobs=-1)(joblib.delayed(sim.simulate_person_load)(\n",
    "    trips_df=df_i, \n",
    "    existing_load=existing_load,\n",
    "    simulation_id=simulation_id,\n",
    "    managed=False,\n",
    "    efficiency=0.3,\n",
    "    frac_work_charging=workfrac,\n",
    "    frac_non_office_charging=0.1,\n",
    "    frac_civic_charging=0.5,\n",
    "    frac_multiunit_charging=multiunitfrac,\n",
    "    frac_singleunit_charging=1.0,\n",
    "    frac_public_dcfc=1.0) \n",
    "    for df_i in df_list)\n",
    "\n",
    "    print('creating charge and loads')\n",
    "    charges_list = [x['charges'] for x in charge_sims]\n",
    "    loads_list = [x['loads'] for x in charge_sims]\n",
    "\n",
    "    # restack the dataframes\n",
    "    charges_df = pd.concat(charges_list)\n",
    "    loads_df = pd.concat(loads_list) # huge ~200 million rows\n",
    "    \n",
    "    charges_df['year'] = year\n",
    "    charges_df['segment'] = 'all'\n",
    "    charges_df['work_frac'] = workfrac\n",
    "    charges_df['multiunit_frac'] = multiunitfrac\n",
    "\n",
    "    loads_df['year'] = year\n",
    "    loads_df['segment'] = 'all'\n",
    "    loads_df['work_frac'] = workfrac\n",
    "    loads_df['multiunit_frac'] = multiunitfrac\n",
    "\n",
    "    charges_df.to_parquet(os.path.join(datadir, f'loads_charges/charges_{year}_by_year_2023-06-06.parquet'))\n",
    "    loads_df.to_parquet(os.path.join(datadir, f'loads_charges/loads_{year}_by_year_2023-06-06.parquet'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_2023 = pd.read_parquet(os.path.join(datadir, 'county_samples/county_sample_personal_sedan_2023.parquet'))\n",
    "test_2025 = pd.read_parquet(os.path.join(datadir, 'county_samples/county_sample_personal_sedan_2025.parquet'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1273081, 1273081)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_2023['activity_id'].nunique(), test_2025['activity_id'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(252329, 252329)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_2023['person_id'].nunique(), test_2025['person_id'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_df = df.drop_duplicates(subset=['person_id'])[['person_id', 'destination_county', 'building_type']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5046603, 3)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
