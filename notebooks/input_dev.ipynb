{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import dask.dataframe as dd\n",
    "datadir = '../../data/'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>county</th>\n",
       "      <th>nEV</th>\n",
       "      <th>efficiency_kwh_mi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022</td>\n",
       "      <td>King</td>\n",
       "      <td>5</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022</td>\n",
       "      <td>Spokane</td>\n",
       "      <td>2</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023</td>\n",
       "      <td>King</td>\n",
       "      <td>6</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023</td>\n",
       "      <td>Spokane</td>\n",
       "      <td>3</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year   county  nEV  efficiency_kwh_mi\n",
       "0  2022     King    5                0.3\n",
       "1  2022  Spokane    2                0.3\n",
       "2  2023     King    6                0.4\n",
       "3  2023  Spokane    3                0.4"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ev_df = pd.DataFrame({\n",
    "    'year': [2022, 2022, 2023, 2023],\n",
    "    'county': ['King', 'Spokane', 'King', 'Spokane'],\n",
    "    'nEV': [5, 2, 6, 3],\n",
    "    'efficiency_kwh_mi': [0.3, 0.3, 0.4, 0.4],\n",
    "})\n",
    "ev_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>person_id</th>\n",
       "      <th>County</th>\n",
       "      <th>Year</th>\n",
       "      <th>efficiency_kwh_mi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>King</td>\n",
       "      <td>2022</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>King</td>\n",
       "      <td>2022</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>King</td>\n",
       "      <td>2022</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>King</td>\n",
       "      <td>2022</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>King</td>\n",
       "      <td>2022</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>Spokane</td>\n",
       "      <td>2022</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>Spokane</td>\n",
       "      <td>2022</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>King</td>\n",
       "      <td>2023</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>King</td>\n",
       "      <td>2023</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>King</td>\n",
       "      <td>2023</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>King</td>\n",
       "      <td>2023</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>King</td>\n",
       "      <td>2023</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>King</td>\n",
       "      <td>2023</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>Spokane</td>\n",
       "      <td>2023</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>Spokane</td>\n",
       "      <td>2023</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>Spokane</td>\n",
       "      <td>2023</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    person_id   County  Year  efficiency_kwh_mi\n",
       "8           8     King  2022                0.3\n",
       "1           1     King  2022                0.3\n",
       "5           5     King  2022                0.3\n",
       "0           0     King  2022                0.3\n",
       "7           7     King  2022                0.3\n",
       "18         18  Spokane  2022                0.3\n",
       "11         11  Spokane  2022                0.3\n",
       "8           8     King  2023                0.4\n",
       "1           1     King  2023                0.4\n",
       "5           5     King  2023                0.4\n",
       "0           0     King  2023                0.4\n",
       "7           7     King  2023                0.4\n",
       "2           2     King  2023                0.4\n",
       "18         18  Spokane  2023                0.4\n",
       "11         11  Spokane  2023                0.4\n",
       "15         15  Spokane  2023                0.4"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Sample dataframe with people and their home county\n",
    "people_df = pd.DataFrame({\n",
    "    'person_id': np.arange(20),\n",
    "    'County': ['King']*10 + ['Spokane']*10,\n",
    "})\n",
    "# Population dataframe with county, year, and number of people to select\n",
    "ev_df = pd.DataFrame({\n",
    "    'Year': [2022, 2022, 2023, 2023],\n",
    "    'County': ['King', 'Spokane', 'King', 'Spokane'],\n",
    "    'nEV': [5, 2, 6, 3],\n",
    "    'efficiency_kwh_mi': [0.3, 0.3, 0.4, 0.4],\n",
    "})\n",
    "\n",
    "selected_people = []\n",
    "for _, row in ev_df.iterrows():\n",
    "    county = row['County']\n",
    "    year = row['Year']\n",
    "    efficiency_kwh_mi = row['efficiency_kwh_mi']\n",
    "    num_to_select = row['nEV']\n",
    "    county_df = people_df[(people_df['County'] == county)]\n",
    "    selected = county_df.sample(n=num_to_select, replace=False, random_state=42)\n",
    "    # Add the year column to the selected dataframe\n",
    "    selected['Year'] = year  \n",
    "    # Add the efficiency column to the selected dataframe\n",
    "    selected['efficiency_kwh_mi'] = efficiency_kwh_mi  \n",
    "    selected_people.append(selected)\n",
    "\n",
    "# Concatenate the selected people into a final dataframe\n",
    "final_df = pd.concat(selected_people)\n",
    "final_df  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ArrowInvalid",
     "evalue": "Could not open Parquet input source '../../data/wa_pop_and_trips_sorted_county_2.parquet/part.10.parquet': Parquet magic bytes not found in footer. Either the file is corrupted or this is not a parquet file.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mArrowInvalid\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m merged_df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_parquet(datadir\u001b[39m+\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mwa_pop_and_trips_sorted_county_2.parquet\u001b[39;49m\u001b[39m'\u001b[39;49m, engine\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mpyarrow\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "File \u001b[0;32m~/mambaforge/lib/python3.10/site-packages/pandas/io/parquet.py:503\u001b[0m, in \u001b[0;36mread_parquet\u001b[0;34m(path, engine, columns, storage_options, use_nullable_dtypes, **kwargs)\u001b[0m\n\u001b[1;32m    456\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    457\u001b[0m \u001b[39mLoad a parquet object from the file path, returning a DataFrame.\u001b[39;00m\n\u001b[1;32m    458\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    499\u001b[0m \u001b[39mDataFrame\u001b[39;00m\n\u001b[1;32m    500\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    501\u001b[0m impl \u001b[39m=\u001b[39m get_engine(engine)\n\u001b[0;32m--> 503\u001b[0m \u001b[39mreturn\u001b[39;00m impl\u001b[39m.\u001b[39;49mread(\n\u001b[1;32m    504\u001b[0m     path,\n\u001b[1;32m    505\u001b[0m     columns\u001b[39m=\u001b[39;49mcolumns,\n\u001b[1;32m    506\u001b[0m     storage_options\u001b[39m=\u001b[39;49mstorage_options,\n\u001b[1;32m    507\u001b[0m     use_nullable_dtypes\u001b[39m=\u001b[39;49muse_nullable_dtypes,\n\u001b[1;32m    508\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m    509\u001b[0m )\n",
      "File \u001b[0;32m~/mambaforge/lib/python3.10/site-packages/pandas/io/parquet.py:251\u001b[0m, in \u001b[0;36mPyArrowImpl.read\u001b[0;34m(self, path, columns, use_nullable_dtypes, storage_options, **kwargs)\u001b[0m\n\u001b[1;32m    244\u001b[0m path_or_handle, handles, kwargs[\u001b[39m\"\u001b[39m\u001b[39mfilesystem\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m _get_path_or_handle(\n\u001b[1;32m    245\u001b[0m     path,\n\u001b[1;32m    246\u001b[0m     kwargs\u001b[39m.\u001b[39mpop(\u001b[39m\"\u001b[39m\u001b[39mfilesystem\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m),\n\u001b[1;32m    247\u001b[0m     storage_options\u001b[39m=\u001b[39mstorage_options,\n\u001b[1;32m    248\u001b[0m     mode\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mrb\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    249\u001b[0m )\n\u001b[1;32m    250\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 251\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapi\u001b[39m.\u001b[39;49mparquet\u001b[39m.\u001b[39;49mread_table(\n\u001b[1;32m    252\u001b[0m         path_or_handle, columns\u001b[39m=\u001b[39;49mcolumns, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs\n\u001b[1;32m    253\u001b[0m     )\u001b[39m.\u001b[39mto_pandas(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mto_pandas_kwargs)\n\u001b[1;32m    254\u001b[0m     \u001b[39mif\u001b[39;00m manager \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39marray\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    255\u001b[0m         result \u001b[39m=\u001b[39m result\u001b[39m.\u001b[39m_as_manager(\u001b[39m\"\u001b[39m\u001b[39marray\u001b[39m\u001b[39m\"\u001b[39m, copy\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/mambaforge/lib/python3.10/site-packages/pyarrow/parquet/core.py:2973\u001b[0m, in \u001b[0;36mread_table\u001b[0;34m(source, columns, use_threads, metadata, schema, use_pandas_metadata, read_dictionary, memory_map, buffer_size, partitioning, filesystem, filters, use_legacy_dataset, ignore_prefixes, pre_buffer, coerce_int96_timestamp_unit, decryption_properties, thrift_string_size_limit, thrift_container_size_limit)\u001b[0m\n\u001b[1;32m   2962\u001b[0m         \u001b[39m# TODO test that source is not a directory or a list\u001b[39;00m\n\u001b[1;32m   2963\u001b[0m         dataset \u001b[39m=\u001b[39m ParquetFile(\n\u001b[1;32m   2964\u001b[0m             source, metadata\u001b[39m=\u001b[39mmetadata, read_dictionary\u001b[39m=\u001b[39mread_dictionary,\n\u001b[1;32m   2965\u001b[0m             memory_map\u001b[39m=\u001b[39mmemory_map, buffer_size\u001b[39m=\u001b[39mbuffer_size,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2970\u001b[0m             thrift_container_size_limit\u001b[39m=\u001b[39mthrift_container_size_limit,\n\u001b[1;32m   2971\u001b[0m         )\n\u001b[0;32m-> 2973\u001b[0m     \u001b[39mreturn\u001b[39;00m dataset\u001b[39m.\u001b[39;49mread(columns\u001b[39m=\u001b[39;49mcolumns, use_threads\u001b[39m=\u001b[39;49muse_threads,\n\u001b[1;32m   2974\u001b[0m                         use_pandas_metadata\u001b[39m=\u001b[39;49muse_pandas_metadata)\n\u001b[1;32m   2976\u001b[0m warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m   2977\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mPassing \u001b[39m\u001b[39m'\u001b[39m\u001b[39muse_legacy_dataset=True\u001b[39m\u001b[39m'\u001b[39m\u001b[39m to get the legacy behaviour is \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   2978\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mdeprecated as of pyarrow 8.0.0, and the legacy implementation will \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   2979\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mbe removed in a future version.\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   2980\u001b[0m     \u001b[39mFutureWarning\u001b[39;00m, stacklevel\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m)\n\u001b[1;32m   2982\u001b[0m \u001b[39mif\u001b[39;00m ignore_prefixes \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/mambaforge/lib/python3.10/site-packages/pyarrow/parquet/core.py:2601\u001b[0m, in \u001b[0;36m_ParquetDatasetV2.read\u001b[0;34m(self, columns, use_threads, use_pandas_metadata)\u001b[0m\n\u001b[1;32m   2593\u001b[0m         index_columns \u001b[39m=\u001b[39m [\n\u001b[1;32m   2594\u001b[0m             col \u001b[39mfor\u001b[39;00m col \u001b[39min\u001b[39;00m _get_pandas_index_columns(metadata)\n\u001b[1;32m   2595\u001b[0m             \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(col, \u001b[39mdict\u001b[39m)\n\u001b[1;32m   2596\u001b[0m         ]\n\u001b[1;32m   2597\u001b[0m         columns \u001b[39m=\u001b[39m (\n\u001b[1;32m   2598\u001b[0m             \u001b[39mlist\u001b[39m(columns) \u001b[39m+\u001b[39m \u001b[39mlist\u001b[39m(\u001b[39mset\u001b[39m(index_columns) \u001b[39m-\u001b[39m \u001b[39mset\u001b[39m(columns))\n\u001b[1;32m   2599\u001b[0m         )\n\u001b[0;32m-> 2601\u001b[0m table \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset\u001b[39m.\u001b[39;49mto_table(\n\u001b[1;32m   2602\u001b[0m     columns\u001b[39m=\u001b[39;49mcolumns, \u001b[39mfilter\u001b[39;49m\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_filter_expression,\n\u001b[1;32m   2603\u001b[0m     use_threads\u001b[39m=\u001b[39;49muse_threads\n\u001b[1;32m   2604\u001b[0m )\n\u001b[1;32m   2606\u001b[0m \u001b[39m# if use_pandas_metadata, restore the pandas metadata (which gets\u001b[39;00m\n\u001b[1;32m   2607\u001b[0m \u001b[39m# lost if doing a specific `columns` selection in to_table)\u001b[39;00m\n\u001b[1;32m   2608\u001b[0m \u001b[39mif\u001b[39;00m use_pandas_metadata:\n",
      "File \u001b[0;32m~/mambaforge/lib/python3.10/site-packages/pyarrow/_dataset.pyx:369\u001b[0m, in \u001b[0;36mpyarrow._dataset.Dataset.to_table\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/mambaforge/lib/python3.10/site-packages/pyarrow/_dataset.pyx:2818\u001b[0m, in \u001b[0;36mpyarrow._dataset.Scanner.to_table\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/mambaforge/lib/python3.10/site-packages/pyarrow/error.pxi:144\u001b[0m, in \u001b[0;36mpyarrow.lib.pyarrow_internal_check_status\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/mambaforge/lib/python3.10/site-packages/pyarrow/error.pxi:100\u001b[0m, in \u001b[0;36mpyarrow.lib.check_status\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mArrowInvalid\u001b[0m: Could not open Parquet input source '../../data/wa_pop_and_trips_sorted_county_2.parquet/part.10.parquet': Parquet magic bytes not found in footer. Either the file is corrupted or this is not a parquet file."
     ]
    }
   ],
   "source": [
    "merged_df = pd.read_parquet(datadir+'wa_pop_and_trips_sorted_county_2.parquet', engine='pyarrow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(merged_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
