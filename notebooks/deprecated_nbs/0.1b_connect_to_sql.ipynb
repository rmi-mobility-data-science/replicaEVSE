{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read in the parquet data tables via dask.DataFrames and create MySQL tables\n",
    "\n",
    "NOTE: this might put weird values into the sql table. I wouldn't trust."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[########################################] | 100% Completed | 34.02 s\n"
     ]
    }
   ],
   "source": [
    "import sqlalchemy as sa\n",
    "import pymysql\n",
    "import dask.dataframe as dd\n",
    "import pandas as pd\n",
    "from dask.diagnostics import ProgressBar\n",
    "import replicaEVSE.sql_wrapper_functions as sql\n",
    "pbar = ProgressBar()\n",
    "pbar.register()\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "with open('../src/metadata/MySQLpwd.txt') as f:\n",
    "    pw = f.readlines()\n",
    "pw = pw[0]\n",
    "\n",
    "# define where the data is\n",
    "popparquet = 'northwest_2021_Q4_population.parquet'\n",
    "tripsatparquet = 'northwest_2021_Q4_saturday_trip.parquet'\n",
    "tripthuparquet = 'northwest_2021_Q4_thursday_trip.parquet'\n",
    "datapath = '../../data/'\n",
    "\n",
    "# read in the data\n",
    "pop_df = dd.read_parquet(datapath + popparquet)\n",
    "trip_sat_df = dd.read_parquet(datapath + tripsatparquet)\n",
    "trip_thu_df = dd.read_parquet(datapath + tripthuparquet)\n",
    "\n",
    "# add in a weekday column to the trips data\n",
    "trip_sat_df['weekday'] = 'saturday'\n",
    "trip_thu_df['weekday'] = 'thursday'\n",
    "\n",
    "# sort the pop data. ~ 5 minutes\n",
    "sorted_pop_df = pop_df.sort_values(by='person_id', ascending=True)\n",
    "\n",
    "# these two tables will get appended so no need to sort\n",
    "# sorted_trip_sat_df = trip_sat_df.sort_values(by='person_id', ascending=True)\n",
    "# sorted_trip_thu_df = trip_thu_df.sort_values(by='person_id', ascending=True)\n",
    "\n",
    "\n",
    "# these are the general parameters for the connection\n",
    "# make sure you defined your password in the metadata folder\n",
    "user = 'root'\n",
    "server = 'localhost'\n",
    "database = 'replica'\n",
    "to_sql_uri = f'mysql+pymysql://{user}:{pw}@{server}/{database}'   \n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Here is the step where we add the data to the MySQL server\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this will create the database if it doesn't exist\n",
    "# if you want to append to an existing database, change if_exists to 'append'\n",
    "sorted_pop_df.to_sql('population', uri=to_sql_uri, if_exists='replace', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SQL didnt like the timedelta dtype so converting it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('<m8[ns]')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trip_sat_df\n",
    "trip_sat_df['start_time'].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('<m8[ns]')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trip_thu_df = dd.read_parquet(datapath + tripthuparquet)\n",
    "trip_thu_df['start_time'].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "trip_thu_df = dd.read_parquet(datapath + tripthuparquet)\n",
    "\n",
    "trip_sat_df['start_time'] = trip_sat_df['start_time'].values.astype('datetime64[ns]')\n",
    "trip_sat_df['end_time'] = trip_sat_df['end_time'].values.astype('datetime64[ns]')\n",
    "\n",
    "trip_thu_df['start_time'] = trip_thu_df['start_time'].values.astype('datetime64[ns]')\n",
    "trip_thu_df['end_time'] = trip_thu_df['end_time'].values.astype('datetime64[ns]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('<M8[ns]')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trip_thu_df['start_time'].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "activity_id                            object\n",
       "person_id                              object\n",
       "mode                                   object\n",
       "travel_purpose                         object\n",
       "previous_activity_type                 object\n",
       "start_time                     datetime64[ns]\n",
       "end_time                       datetime64[ns]\n",
       "distance_miles                        float64\n",
       "vehicle_type                           object\n",
       "origin_bgrp                            object\n",
       "origin_bgrp_lat                       float64\n",
       "origin_bgrp_lng                       float64\n",
       "destination_bgrp                       object\n",
       "destination_bgrp_lat                  float64\n",
       "destination_bgrp_lng                  float64\n",
       "origin_land_use_l1                     object\n",
       "origin_land_use_l2                     object\n",
       "origin_building_use_l1                 object\n",
       "origin_building_use_l2                 object\n",
       "destination_land_use_l1                object\n",
       "destination_land_use_l2                object\n",
       "destination_building_use_l1            object\n",
       "destination_building_use_l2            object\n",
       "origin_lat                            float64\n",
       "origin_lng                            float64\n",
       "destination_lat                       float64\n",
       "destination_lng                       float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trip_thu_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[########################################] | 100% Completed | 38m 42s\n",
      "[########################################] | 100% Completed | 38m 42s\n"
     ]
    }
   ],
   "source": [
    "trip_sat_df.to_sql('trips', uri=to_sql_uri, if_exists='replace', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[########################################] | 100% Completed | 42m 49s\n",
      "[########################################] | 100% Completed | 42m 49s\n"
     ]
    }
   ],
   "source": [
    "trip_thu_df.to_sql('trips', uri=to_sql_uri, if_exists='append', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# create tables in our replica db to add values to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_charges_table=\"\"\"\n",
    "CREATE TABLE charges (\n",
    "  charge_id VARCHAR(24) PRIMARY KEY,\n",
    "  activity_id VARCHAR(20),\n",
    "  simulation_id VARCHAR(4),\n",
    "  charger_power_kW DECIMAL(5,1),\n",
    "  charge_energy_used_kWh DECIMAL(4,1),\n",
    "  charge_opportunity_remaining_kWh DECIMAL(5,1)\n",
    "  );\n",
    "\"\"\"\n",
    "create_load_table=\"\"\"\n",
    "CREATE TABLE loads (\n",
    "  load_segment_id VARCHAR(26) PRIMARY KEY,\n",
    "  charge_id VARCHAR(24),\n",
    "  window_start_time TIME,\n",
    "  window_end_time TIME,\n",
    "  load_kW DECIMAL(5,1)\n",
    "  );\n",
    "\"\"\"\n",
    "create_simulation_table=\"\"\"\n",
    "CREATE TABLE simulation_runs (\n",
    "  simulation_id VARCHAR(4) PRIMARY KEY,\n",
    "  simulation_date DATETIME,\n",
    "  simulation_attributes VARCHAR(200)\n",
    "  );\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MySQL Database connection successful\n"
     ]
    }
   ],
   "source": [
    "import replicaEVSE.sql_wrapper_functions as sql\n",
    "connection_replica = sql.create_db_connection(\"localhost\", \"root\", pw, 'replica') # Connect to the Database\n",
    "sql.execute_query(connection_replica, 'DROP TABLE IF EXISTS loads;')\n",
    "sql.execute_query(connection_replica, 'DROP TABLE IF EXISTS charges;')\n",
    "sql.execute_query(connection_replica, 'DROP TABLE IF EXISTS simulation_runs;')\n",
    "sql.execute_query(connection_replica, create_charges_table) # Execute our defined query\n",
    "sql.execute_query(connection_replica, create_load_table) # Execute our defined query\n",
    "sql.execute_query(connection_replica, create_simulation_table) # Execute our defined query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
